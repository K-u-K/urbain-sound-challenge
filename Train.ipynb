{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUojL_DcLpOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98aEackSM3a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten, Conv1D, LeakyReLU, BatchNormalization, AveragePooling1D, MaxPooling1D\n",
        "from keras.layers import LSTM\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from contextlib import redirect_stdout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCbJYYK8Ndga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths\n",
        "directory = \"drive/My Drive/UE_Proell\"\n",
        "preprocessed = f\"{directory}/preprocessed\"\n",
        "result = f\"{directory}/result\"\n",
        "\n",
        "# hyper parameter\n",
        "loss = 'categorical_crossentropy'\n",
        "learning_rate = 0.01\n",
        "leaky_alpha = 0.01\n",
        "dropout = 0.3\n",
        "batch_size = 40\n",
        "epochs = 250\n",
        "\n",
        "# configuration parameter\n",
        "save_model_infs = False\n",
        "validation_split = 0.2\n",
        "patience = 20\n",
        "verbose = 1\n",
        "seed = 42\n",
        "\n",
        "# labels\n",
        "labels = [\n",
        "    \"air conditioner\",\n",
        "    \"car horn\",\n",
        "    \"children playing\",\n",
        "    \"dog bark\",\n",
        "    \"drilling\",\n",
        "    \"engine idling\",\n",
        "    \"gun shot\",\n",
        "    \"jackhammer\",\n",
        "    \"siren\",\n",
        "    \"street music\"\n",
        "]\n",
        "\n",
        "# others\n",
        "model_name = \"urbaner\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaWIPFmrO5H4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(result, exist_ok=True)\n",
        "\n",
        "X_train, y_train = np.load(f\"{preprocessed}/X_train.npy\"), np.load(f\"{preprocessed}/y_train.npy\")\n",
        "X_test, y_test = np.load(f\"{preprocessed}/X_test.npy\"), np.load(f\"{preprocessed}/y_test.npy\")\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_split, random_state=seed, stratify=y_train)\n",
        "\n",
        "num_of_labels = y_train.shape[1]\n",
        "\n",
        "print(\"X_train\", X_train.shape, \"-\", \"y_train\", y_train.shape)\n",
        "print(\"X_valid\", X_valid.shape, \"-\", \"y_valid\", y_valid.shape)\n",
        "print(\"X_test\", X_test.shape, \"-\", \"y_test\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsLyMjxwOVvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDNN(input_shape):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(512, input_shape=input_shape, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Dense(num_of_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0kgt77fQGBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getCNN(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters = 1, kernel_size = 3, input_shape=input_shape))\n",
        "    model.add(LeakyReLU(alpha = leaky_alpha))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_of_labels, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAUriXYVM_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLSTM(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(32, input_shape=input_shape))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(num_of_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVb8gg_0PvFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "networks = {\n",
        "    \"dnn\": lambda: getDNN((40, )),\n",
        "    \"cnn\": lambda: getCNN((40, 1)),\n",
        "    \"lstm\": lambda: getLSTM((1, 40))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv6ucZ_vJGjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(confusion_matrix, class_names, **kwargs):\n",
        "  df_cm = pd.DataFrame(confusion_matrix, index = class_names, columns = class_names)\n",
        "  plt.figure(figsize = (10,7))\n",
        "  sns.heatmap(df_cm, annot=True, cmap=kwargs[\"cmap\"])\n",
        "  plt.savefig(f\"{kwargs['result_path']}/confusion_matrix.png\", dpi=400)\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9KcO7LDag3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model_information(network, hist, scores, y_test_indices, y_pred_indices):\n",
        "  result_path = f\"{result}/{network}\"\n",
        "  if not os.path.exists(result_path):\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "  model.save(f\"{result_path}/{model_name}\")\n",
        "\n",
        "  # plot history for accuracy\n",
        "  plt.figure()\n",
        "  plt.ioff()\n",
        "  plt.plot(hist.history['acc'])\n",
        "  plt.plot(hist.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.savefig(f\"{result_path}/accuracy_{model_name}\")\n",
        "\n",
        "  # plot history for loss\n",
        "  plt.figure()\n",
        "  plt.ioff()\n",
        "  plt.plot(hist.history['loss'])\n",
        "  plt.plot(hist.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.savefig(f\"{result_path}/loss_{model_name}\")\n",
        "\n",
        "  # generate other metrics + plot confusion matrixs\n",
        "  confusion_matrix = metrics.confusion_matrix(y_test_indices, y_pred_indices)\n",
        "  report           = metrics.classification_report(y_test_indices, y_pred_indices, target_names=labels, digits=3)\n",
        "  plot_confusion_matrix(confusion_matrix, labels, cmap=\"Blues\", result_path=result_path)\n",
        "\n",
        "  # save detail information\n",
        "  with open(f\"{result_path}/{model_name}.txt\",\"w+\") as f:\n",
        "      f.write('Trainingparameter:\\n')\n",
        "      f.write('ValidationSplit: {0}\\n'.format(validation_split))\n",
        "      f.write('Batchsize: {0}\\n'.format(batch_size))\n",
        "      f.write('Epochs: {0}\\n'.format(epochs))\n",
        "      f.write('Patience for Early Stopping: {0}\\n'.format(patience))\n",
        "      f.write('\\n')\n",
        "      f.write('Results:\\n')\n",
        "      f.write('Trainingaccuracy: {0}\\n'.format(hist.history['acc'][-1]*100))\n",
        "      f.write('Testaccuracy: {0}\\n'.format(scores[1] * 100))\n",
        "      f.write('\\n')\n",
        "      f.write('Confusion matrix\\n')\n",
        "      f.write(str(confusion_matrix))\n",
        "      f.write('\\n\\n')\n",
        "      f.write(\"Classification report\\n\")\n",
        "      f.write(report)\n",
        "      f.write(\"\\n\")\n",
        "      f.write('Modelarchitecture:\\n')\n",
        "      with redirect_stdout(f):\n",
        "          model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MDfL-nQuvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for network, model_function in networks.items():\n",
        "  print(f\"[{network}] Train network\")\n",
        "\n",
        "  model = model_function()\n",
        "  model.compile(Adam(lr=learning_rate), loss=loss, metrics=['accuracy'])\n",
        "\n",
        "  callbacks = [\n",
        "        EarlyStopping(monitor=\"loss\", patience=patience, verbose=0, mode=\"auto\"),\n",
        "  ]\n",
        "  \n",
        "  X = {\n",
        "      \"train\": X_train.copy(),\n",
        "      \"test\": X_test.copy(),\n",
        "      \"valid\": X_valid.copy()\n",
        "  }\n",
        "\n",
        "  if network == \"cnn\":\n",
        "    X[\"train\"] = np.expand_dims(X[\"train\"], axis=2)\n",
        "    X[\"test\"] = np.expand_dims(X[\"test\"], axis=2)\n",
        "    X[\"valid\"] = np.expand_dims(X[\"valid\"], axis=2)\n",
        "\n",
        "  if network == \"lstm\":\n",
        "    X[\"train\"] = np.expand_dims(X[\"train\"], axis=1)\n",
        "    X[\"test\"] = np.expand_dims(X[\"test\"], axis=1)\n",
        "    X[\"valid\"] = np.expand_dims(X[\"valid\"], axis=1)\n",
        "\n",
        "  print(f\"Current shape for input values: {X['train'].shape}\")\n",
        "\n",
        "  hist = model.fit(X[\"train\"], y_train, validation_data=(X[\"valid\"], y_valid), batch_size=batch_size, epochs=epochs, shuffle=True, verbose=verbose, callbacks=callbacks)\n",
        "  \n",
        "  scores = model.evaluate(X[\"test\"], y_test, verbose=0)\n",
        "  print(f\"[{network}] Testaccuracy {scores[1] * 100}\")\n",
        "\n",
        "  y_pred_indices = np.argmax(model.predict(X[\"test\"]), axis=1)\n",
        "  y_test_indices = np.argmax(y_test, axis=1)\n",
        "\n",
        "  if save_model_infs:\n",
        "    save_model_information(network, hist, scores, y_test_indices, y_pred_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8f_TW8bvHZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}